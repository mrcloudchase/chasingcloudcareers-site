"use strict";(self.webpackChunkchasingcloudcareers=self.webpackChunkchasingcloudcareers||[]).push([[5039],{8453:(n,e,i)=>{i.d(e,{R:()=>a,x:()=>t});var r=i(6540);const s={},l=r.createContext(s);function a(n){const e=r.useContext(l);return r.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function t(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:a(n.components),r.createElement(l.Provider,{value:e},n.children)}},9466:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>o,contentTitle:()=>t,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"machine-learning-engineering/ml-fundamentals","title":"ML Fundamentals","description":"Mathematical Foundations for Machine Learning","source":"@site/docs/machine-learning-engineering/01-ml-fundamentals.md","sourceDirName":"machine-learning-engineering","slug":"/machine-learning-engineering/ml-fundamentals","permalink":"/docs/machine-learning-engineering/ml-fundamentals","draft":false,"unlisted":false,"editUrl":"https://github.com/mrcloudchase/chasingcloudcareers-site/tree/main/docs/machine-learning-engineering/01-ml-fundamentals.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Getting Started with Machine Learning Engineering","permalink":"/docs/machine-learning-engineering/getting-started"},"next":{"title":"Data Engineering","permalink":"/docs/machine-learning-engineering/data-engineering"}}');var s=i(4848),l=i(8453);const a={sidebar_position:3},t="ML Fundamentals",o={},d=[{value:"Mathematical Foundations for Machine Learning",id:"mathematical-foundations-for-machine-learning",level:2},{value:"Supervised Learning Algorithms",id:"supervised-learning-algorithms",level:2},{value:"Unsupervised Learning and Dimensionality Reduction",id:"unsupervised-learning-and-dimensionality-reduction",level:2},{value:"Deep Learning Fundamentals",id:"deep-learning-fundamentals",level:2},{value:"Model Selection and Validation",id:"model-selection-and-validation",level:2},{value:"Feature Engineering and Selection",id:"feature-engineering-and-selection",level:2},{value:"Evaluation Metrics and Performance Analysis",id:"evaluation-metrics-and-performance-analysis",level:2},{value:"Algorithm Implementation from Scratch",id:"algorithm-implementation-from-scratch",level:2}];function c(n){const e={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,l.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"ml-fundamentals",children:"ML Fundamentals"})}),"\n",(0,s.jsx)(e.h2,{id:"mathematical-foundations-for-machine-learning",children:"Mathematical Foundations for Machine Learning"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"What you Need to Know"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Linear Algebra in Machine Learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Vector spaces and linear transformations in ML contexts"}),"\n",(0,s.jsx)(e.li,{children:"Matrix operations for data representation and model parameters"}),"\n",(0,s.jsx)(e.li,{children:"Eigendecomposition and Singular Value Decomposition (SVD)"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://github.com/fastai/numerical-linear-algebra",children:"Linear Algebra for ML"})," - Fast.ai computational linear algebra course"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://explained.ai/matrix-calculus/",children:"Matrix Calculus for Deep Learning"})," - Matrix derivatives and gradients"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://cs229.stanford.edu/section/cs229-linalg.pdf",children:"Linear Algebra Review - CS229"})," - Stanford ML linear algebra notes"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Calculus and Optimization Theory"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Gradient computation and chain rule for backpropagation"}),"\n",(0,s.jsx)(e.li,{children:"Convex optimization and global vs local minima"}),"\n",(0,s.jsx)(e.li,{children:"Lagrange multipliers and constrained optimization"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://web.stanford.edu/~boyd/cvxbook/",children:"Convex Optimization - Boyd"})," - Free convex optimization textbook"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://arxiv.org/abs/1909.03550",children:"Optimization for Machine Learning"})," - Modern optimization techniques"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://colah.github.io/posts/2015-08-Backprop/",children:"Calculus on Computational Graphs"})," - Backpropagation explained"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Probability Theory and Statistical Learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Bayesian inference and maximum likelihood estimation"}),"\n",(0,s.jsx)(e.li,{children:"Probability distributions and their ML applications"}),"\n",(0,s.jsx)(e.li,{children:"Information theory and entropy in machine learning"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://probml.github.io/pml-book/",children:"Probabilistic Machine Learning"})," - Kevin Murphy's comprehensive ML book"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"http://www.inference.org.uk/itprnn/book.pdf",children:"Information Theory - MacKay"})," - Information theory and inference"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://www.coursera.org/learn/bayesian-methods-in-machine-learning",children:"Bayesian Methods for Machine Learning"})," - HSE University course"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"supervised-learning-algorithms",children:"Supervised Learning Algorithms"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"What you Need to Know"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Linear Models and Regularization"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Linear regression with mathematical derivation"}),"\n",(0,s.jsx)(e.li,{children:"Ridge, Lasso, and Elastic Net regularization"}),"\n",(0,s.jsx)(e.li,{children:"Logistic regression and maximum likelihood"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://hastie.su.domains/ElemStatLearn/printings/ESLII_print12_toc.pdf",children:"Linear Models - ESL"})," - Elements of Statistical Learning chapters"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://machinelearningmastery.com/regularization-for-reducing-generalization-error/",children:"Regularization Tutorial"})," - Ridge and Lasso implementation"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html",children:"Logistic Regression Math"})," - Mathematical foundations"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Tree-Based Methods and Ensemble Learning"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Decision trees and information gain criteria"}),"\n",(0,s.jsx)(e.li,{children:"Random Forest and bagging techniques"}),"\n",(0,s.jsx)(e.li,{children:"Gradient boosting and XGBoost implementation"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://scikit-learn.org/stable/modules/tree.html",children:"Decision Trees - Scikit-learn"})," - Decision tree algorithms and implementation"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf",children:"Random Forest Paper"})," - Breiman's original random forest paper"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://xgboost.readthedocs.io/en/stable/",children:"XGBoost Documentation"})," - Gradient boosting framework"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Support Vector Machines and Kernel Methods"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"SVM optimization problem and dual formulation"}),"\n",(0,s.jsx)(e.li,{children:"Kernel trick and non-linear transformations"}),"\n",(0,s.jsx)(e.li,{children:"Soft margin and regularization in SVMs"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://web.mit.edu/6.034/wwwbob/svm-notes-long-08.pdf",children:"SVM Tutorial"})," - MIT SVM mathematical foundations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://alex.smola.org/drafts/thebook.pdf",children:"Kernel Methods"})," - Learning with Kernels textbook"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://scikit-learn.org/stable/modules/svm.html",children:"SVM Implementation"})," - Scikit-learn SVM guide"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"unsupervised-learning-and-dimensionality-reduction",children:"Unsupervised Learning and Dimensionality Reduction"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"What you Need to Know"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Clustering Algorithms"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"K-means clustering and expectation-maximization"}),"\n",(0,s.jsx)(e.li,{children:"Hierarchical clustering and linkage criteria"}),"\n",(0,s.jsx)(e.li,{children:"DBSCAN and density-based clustering"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://scikit-learn.org/stable/modules/clustering.html",children:"Clustering Algorithms"})," - Comprehensive clustering guide"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://www.cs.cmu.edu/~mgormley/courses/10701-f16/slides/lecture14-em.pdf",children:"K-means Mathematical Analysis"})," - CMU clustering lecture"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf",children:"DBSCAN Paper"})," - Original DBSCAN algorithm"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Principal Component Analysis and Matrix Factorization"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"PCA mathematical derivation and implementation"}),"\n",(0,s.jsx)(e.li,{children:"Singular Value Decomposition applications"}),"\n",(0,s.jsx)(e.li,{children:"Non-negative Matrix Factorization (NMF)"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://arxiv.org/abs/1404.1100",children:"PCA Tutorial"})," - Principal Component Analysis explained"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm",children:"SVD and PCA"})," - MIT SVD tutorial"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf",children:"Matrix Factorization"})," - Netflix recommendation system"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Manifold Learning and Non-linear Dimensionality Reduction"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"t-SNE for visualization and clustering"}),"\n",(0,s.jsx)(e.li,{children:"UMAP for dimensionality reduction"}),"\n",(0,s.jsx)(e.li,{children:"Autoencoders for non-linear feature learning"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://jmlr.org/papers/v9/vandermaaten08a.html",children:"t-SNE Paper"})," - Original t-SNE algorithm"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://umap-learn.readthedocs.io/en/latest/",children:"UMAP Documentation"})," - Uniform Manifold Approximation"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://blog.keras.io/building-autoencoders-in-keras.html",children:"Autoencoder Tutorial"})," - Keras autoencoder implementation"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"deep-learning-fundamentals",children:"Deep Learning Fundamentals"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"What you Need to Know"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Neural Network Architecture and Training"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Multi-layer perceptrons and universal approximation theorem"}),"\n",(0,s.jsx)(e.li,{children:"Backpropagation algorithm mathematical derivation"}),"\n",(0,s.jsx)(e.li,{children:"Gradient descent variants and optimization techniques"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://www.deeplearningbook.org/",children:"Deep Learning Book"})," - Goodfellow, Bengio, and Courville comprehensive text"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"http://neuralnetworksanddeeplearning.com/",children:"Neural Networks and Deep Learning"})," - Nielsen's online book"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://www.youtube.com/watch?v=tIeHLnjs5U8",children:"Backpropagation Calculus"})," - 3Blue1Brown backprop explanation"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Convolutional Neural Networks"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Convolution operation and feature maps"}),"\n",(0,s.jsx)(e.li,{children:"CNN architectures (LeNet, AlexNet, VGG, ResNet)"}),"\n",(0,s.jsx)(e.li,{children:"Pooling layers and spatial hierarchies"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://cs231n.github.io/convolutional-networks/",children:"CNN for Visual Recognition"})," - Stanford CS231n CNN guide"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://arxiv.org/abs/1605.07678",children:"CNN Architectures"})," - Survey of CNN architectures"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://arxiv.org/abs/1512.03385",children:"ResNet Paper"})," - Deep residual learning"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Recurrent Neural Networks and Sequence Modeling"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"RNN architecture and vanishing gradient problem"}),"\n",(0,s.jsx)(e.li,{children:"LSTM and GRU for long-term dependencies"}),"\n",(0,s.jsx)(e.li,{children:"Attention mechanisms and Transformer architecture"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://colah.github.io/posts/2015-08-Understanding-LSTMs/",children:"Understanding LSTMs"})," - LSTM architecture explained"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://arxiv.org/abs/1706.03762",children:"Attention Is All You Need"})," - Original Transformer paper"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://karpathy.github.io/2015/05/21/rnn-effectiveness/",children:"RNN Tutorial"})," - Karpathy's RNN guide"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"model-selection-and-validation",children:"Model Selection and Validation"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"What you Need to Know"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Cross-Validation Techniques"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"K-fold cross-validation and stratified sampling"}),"\n",(0,s.jsx)(e.li,{children:"Leave-one-out and bootstrap validation"}),"\n",(0,s.jsx)(e.li,{children:"Time series cross-validation for temporal data"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://scikit-learn.org/stable/modules/cross_validation.html",children:"Cross-Validation"})," - Scikit-learn CV documentation"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://web.stanford.edu/~hastie/Papers/ESLII.pdf",children:"Model Selection"})," - ESL model assessment chapter"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://robjhyndman.com/hyndsight/tscv/",children:"Time Series CV"})," - Time series validation techniques"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Bias-Variance Tradeoff and Regularization"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Mathematical analysis of bias-variance decomposition"}),"\n",(0,s.jsx)(e.li,{children:"Regularization techniques and their effects"}),"\n",(0,s.jsx)(e.li,{children:"Early stopping and dropout as regularization"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"http://scott.fortmann-roe.com/docs/BiasVariance.html",children:"Bias-Variance Tradeoff"})," - Visual bias-variance explanation"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://arxiv.org/abs/1701.05369",children:"Regularization in Deep Learning"})," - Comprehensive regularization survey"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://jmlr.org/papers/v15/srivastava14a.html",children:"Dropout Paper"})," - Original dropout technique"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Hyperparameter Optimization"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Grid search and random search strategies"}),"\n",(0,s.jsx)(e.li,{children:"Bayesian optimization and Gaussian processes"}),"\n",(0,s.jsx)(e.li,{children:"Automated hyperparameter tuning techniques"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://arxiv.org/abs/1206.2944",children:"Hyperparameter Optimization"})," - Bergstra and Bengio survey"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://arxiv.org/abs/1012.2599",children:"Bayesian Optimization"})," - Gaussian process optimization"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://optuna.readthedocs.io/en/stable/tutorial/index.html",children:"Optuna Tutorial"})," - Automated hyperparameter optimization"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"feature-engineering-and-selection",children:"Feature Engineering and Selection"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"What you Need to Know"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Feature Extraction and Transformation"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Polynomial features and interaction terms"}),"\n",(0,s.jsx)(e.li,{children:"Feature scaling and normalization techniques"}),"\n",(0,s.jsx)(e.li,{children:"Handling categorical variables and encoding"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/",children:"Feature Engineering"})," - O'Reilly feature engineering book"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://scikit-learn.org/stable/modules/preprocessing.html",children:"Preprocessing Data"})," - Scikit-learn preprocessing guide"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://contrib.scikit-learn.org/category_encoders/",children:"Categorical Encoding"})," - Advanced categorical encoding techniques"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Feature Selection Methods"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Filter methods (correlation, mutual information)"}),"\n",(0,s.jsx)(e.li,{children:"Wrapper methods (recursive feature elimination)"}),"\n",(0,s.jsx)(e.li,{children:"Embedded methods (Lasso, tree-based importance)"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://scikit-learn.org/stable/modules/feature_selection.html",children:"Feature Selection"})," - Comprehensive feature selection guide"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://arxiv.org/abs/1106.2418",children:"Information Theory Feature Selection"})," - Mutual information methods"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://machinelearningmastery.com/rfe-feature-selection-in-python/",children:"Recursive Feature Elimination"})," - RFE implementation"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"evaluation-metrics-and-performance-analysis",children:"Evaluation Metrics and Performance Analysis"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"What you Need to Know"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Classification Metrics"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Accuracy, precision, recall, and F1-score analysis"}),"\n",(0,s.jsx)(e.li,{children:"ROC curves and Area Under Curve (AUC)"}),"\n",(0,s.jsx)(e.li,{children:"Multi-class and multi-label evaluation metrics"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics",children:"Classification Metrics"})," - Comprehensive metrics guide"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc",children:"ROC and AUC Explained"})," - Google's ROC tutorial"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://arxiv.org/abs/2008.05756",children:"Multi-class Metrics"})," - Multi-class evaluation survey"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Regression Metrics"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Mean Squared Error (MSE) and Root Mean Squared Error (RMSE)"}),"\n",(0,s.jsx)(e.li,{children:"Mean Absolute Error (MAE) and robust metrics"}),"\n",(0,s.jsx)(e.li,{children:"R-squared and adjusted R-squared interpretation"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics",children:"Regression Metrics"})," - Regression evaluation guide"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://blog.minitab.com/en/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit",children:"Understanding R-squared"})," - R-squared interpretation"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://arxiv.org/abs/1608.06048",children:"Robust Regression Metrics"})," - Alternative regression metrics"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"algorithm-implementation-from-scratch",children:"Algorithm Implementation from Scratch"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"What you Need to Know"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Linear Algebra Implementation"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Matrix operations without NumPy dependencies"}),"\n",(0,s.jsx)(e.li,{children:"Gradient computation and optimization loops"}),"\n",(0,s.jsx)(e.li,{children:"Numerical stability and computational efficiency"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://github.com/rushter/MLAlgorithms",children:"ML Algorithms from Scratch"})," - Pure Python implementations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://github.com/fastai/numerical-linear-algebra",children:"Numerical Linear Algebra"})," - Computational linear algebra course"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf",children:"Matrix Cookbook"})," - Matrix identities and derivatives"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Optimization Algorithm Implementation"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Gradient descent variants (SGD, Adam, RMSprop)"}),"\n",(0,s.jsx)(e.li,{children:"Newton's method and quasi-Newton methods"}),"\n",(0,s.jsx)(e.li,{children:"Coordinate descent and proximal methods"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Resources:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://arxiv.org/abs/1609.04747",children:"Optimization Algorithms"})," - Overview of optimization for deep learning"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://ruder.io/optimizing-gradient-descent/",children:"SGD Variants"})," - Gradient descent optimization overview"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"https://web.stanford.edu/~boyd/papers/pdf/prox_algs.pdf",children:"Proximal Algorithms"})," - Proximal optimization methods"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Ready to Engineer Data?"})," Continue to ",(0,s.jsx)(e.a,{href:"/docs/machine-learning-engineering/data-engineering",children:"Module 2: Data Engineering"})," to master data pipelines, preprocessing, and feature engineering for machine learning systems."]})]})}function h(n={}){const{wrapper:e}={...(0,l.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(c,{...n})}):c(n)}}}]);