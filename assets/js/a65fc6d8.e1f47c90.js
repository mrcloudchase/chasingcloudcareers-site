"use strict";(self.webpackChunkchasingcloudcareers=self.webpackChunkchasingcloudcareers||[]).push([[560],{6476:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>c,contentTitle:()=>i,default:()=>u,frontMatter:()=>o,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"devops-engineering/infrastructure-as-code","title":"Infrastructure as Code and Configuration Management","description":"Master infrastructure automation through code, enabling consistent, scalable, and maintainable infrastructure deployments across multiple cloud providers and environments.","source":"@site/docs/devops-engineering/03-infrastructure-as-code.md","sourceDirName":"devops-engineering","slug":"/devops-engineering/infrastructure-as-code","permalink":"/chasingcloudcareers-site/docs/devops-engineering/infrastructure-as-code","draft":false,"unlisted":false,"editUrl":"https://github.com/mrcloudchase/chasingcloudcareers-site/tree/main/docs/devops-engineering/03-infrastructure-as-code.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"CI/CD Pipelines and Automation","permalink":"/chasingcloudcareers-site/docs/devops-engineering/cicd-pipelines"},"next":{"title":"Containerization and Orchestration","permalink":"/chasingcloudcareers-site/docs/devops-engineering/containerization-orchestration"}}');var a=r(4848),s=r(8453);const o={sidebar_position:5},i="Infrastructure as Code and Configuration Management",c={},l=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"1. Infrastructure as Code Fundamentals",id:"1-infrastructure-as-code-fundamentals",level:2},{value:"Terraform Mastery",id:"terraform-mastery",level:3},{value:"Multi-Cloud Infrastructure Patterns",id:"multi-cloud-infrastructure-patterns",level:3},{value:"Free Resources",id:"free-resources",level:3},{value:"2. Configuration Management",id:"2-configuration-management",level:2},{value:"Ansible Automation",id:"ansible-automation",level:3},{value:"Infrastructure Testing and Validation",id:"infrastructure-testing-and-validation",level:3},{value:"Free Resources",id:"free-resources-1",level:3},{value:"3. State Management and Collaboration",id:"3-state-management-and-collaboration",level:2},{value:"Advanced State Management",id:"advanced-state-management",level:3},{value:"Free Resources",id:"free-resources-2",level:3},{value:"Hands-On Exercises",id:"hands-on-exercises",level:2},{value:"Exercise 1: Multi-Cloud Infrastructure Deployment",id:"exercise-1-multi-cloud-infrastructure-deployment",level:3},{value:"Exercise 2: Configuration Management at Scale",id:"exercise-2-configuration-management-at-scale",level:3},{value:"Exercise 3: Infrastructure State Management",id:"exercise-3-infrastructure-state-management",level:3},{value:"Assessment Questions",id:"assessment-questions",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"Additional Resources",id:"additional-resources",level:2},{value:"Tools and Platforms",id:"tools-and-platforms",level:3},{value:"Advanced Topics",id:"advanced-topics",level:3}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"infrastructure-as-code-and-configuration-management",children:"Infrastructure as Code and Configuration Management"})}),"\n",(0,a.jsx)(e.p,{children:"Master infrastructure automation through code, enabling consistent, scalable, and maintainable infrastructure deployments across multiple cloud providers and environments."}),"\n",(0,a.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(e.p,{children:"By the end of this module, you will:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Design and implement Infrastructure as Code (IaC) solutions using Terraform and cloud-native tools"}),"\n",(0,a.jsx)(e.li,{children:"Master configuration management with Ansible, Chef, and Puppet"}),"\n",(0,a.jsx)(e.li,{children:"Build multi-cloud infrastructure automation strategies"}),"\n",(0,a.jsx)(e.li,{children:"Implement infrastructure security and compliance automation"}),"\n",(0,a.jsx)(e.li,{children:"Develop infrastructure monitoring, cost optimization, and state management practices"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"1-infrastructure-as-code-fundamentals",children:"1. Infrastructure as Code Fundamentals"}),"\n",(0,a.jsx)(e.h3,{id:"terraform-mastery",children:"Terraform Mastery"}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Advanced Terraform Configuration:"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-hcl",children:'# main.tf - Multi-environment infrastructure\nterraform {\n  required_version = ">= 1.0"\n  required_providers {\n    aws = {\n      source  = "hashicorp/aws"\n      version = "~> 5.0"\n    }\n    kubernetes = {\n      source  = "hashicorp/kubernetes"\n      version = "~> 2.0"\n    }\n    helm = {\n      source  = "hashicorp/helm"\n      version = "~> 2.0"\n    }\n  }\n  \n  backend "s3" {\n    bucket         = "terraform-state-bucket"\n    key            = "infrastructure/terraform.tfstate"\n    region         = "us-west-2"\n    encrypt        = true\n    dynamodb_table = "terraform-locks"\n  }\n}\n\n# Provider configurations\nprovider "aws" {\n  region = var.aws_region\n  \n  default_tags {\n    tags = {\n      Environment   = var.environment\n      Project       = var.project_name\n      ManagedBy     = "terraform"\n      Owner         = var.owner\n      CostCenter    = var.cost_center\n    }\n  }\n}\n\n# Data sources\ndata "aws_availability_zones" "available" {\n  state = "available"\n}\n\ndata "aws_ami" "amazon_linux" {\n  most_recent = true\n  owners      = ["amazon"]\n  \n  filter {\n    name   = "name"\n    values = ["amzn2-ami-hvm-*-x86_64-gp2"]\n  }\n}\n\n# Local values for computed configurations\nlocals {\n  azs = slice(data.aws_availability_zones.available.names, 0, 3)\n  \n  common_tags = {\n    Environment = var.environment\n    Project     = var.project_name\n    ManagedBy   = "terraform"\n  }\n  \n  vpc_cidr = "10.0.0.0/16"\n  \n  private_subnets = [\n    "10.0.1.0/24",\n    "10.0.2.0/24",\n    "10.0.3.0/24"\n  ]\n  \n  public_subnets = [\n    "10.0.101.0/24",\n    "10.0.102.0/24",\n    "10.0.103.0/24"\n  ]\n}\n\n# VPC Module\nmodule "vpc" {\n  source = "terraform-aws-modules/vpc/aws"\n  \n  name = "${var.project_name}-${var.environment}-vpc"\n  cidr = local.vpc_cidr\n  \n  azs             = local.azs\n  private_subnets = local.private_subnets\n  public_subnets  = local.public_subnets\n  \n  enable_nat_gateway = true\n  enable_vpn_gateway = false\n  enable_dns_hostnames = true\n  enable_dns_support = true\n  \n  # VPC Flow Logs\n  enable_flow_log                      = true\n  create_flow_log_cloudwatch_iam_role  = true\n  create_flow_log_cloudwatch_log_group = true\n  \n  tags = local.common_tags\n}\n\n# Security Groups\nresource "aws_security_group" "web" {\n  name_prefix = "${var.project_name}-web-"\n  vpc_id      = module.vpc.vpc_id\n  \n  ingress {\n    from_port   = 80\n    to_port     = 80\n    protocol    = "tcp"\n    cidr_blocks = ["0.0.0.0/0"]\n  }\n  \n  ingress {\n    from_port   = 443\n    to_port     = 443\n    protocol    = "tcp"\n    cidr_blocks = ["0.0.0.0/0"]\n  }\n  \n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = "-1"\n    cidr_blocks = ["0.0.0.0/0"]\n  }\n  \n  tags = merge(local.common_tags, {\n    Name = "${var.project_name}-web-sg"\n  })\n}\n\n# Application Load Balancer\nresource "aws_lb" "main" {\n  name               = "${var.project_name}-${var.environment}-alb"\n  internal           = false\n  load_balancer_type = "application"\n  security_groups    = [aws_security_group.web.id]\n  subnets           = module.vpc.public_subnets\n  \n  enable_deletion_protection = var.environment == "production"\n  \n  access_logs {\n    bucket  = aws_s3_bucket.alb_logs.bucket\n    prefix  = "alb"\n    enabled = true\n  }\n  \n  tags = local.common_tags\n}\n\n# EKS Cluster\nmodule "eks" {\n  source = "terraform-aws-modules/eks/aws"\n  \n  cluster_name    = "${var.project_name}-${var.environment}"\n  cluster_version = "1.28"\n  \n  vpc_id     = module.vpc.vpc_id\n  subnet_ids = module.vpc.private_subnets\n  \n  # Cluster endpoint configuration\n  cluster_endpoint_private_access = true\n  cluster_endpoint_public_access  = true\n  cluster_endpoint_public_access_cidrs = var.allowed_cidr_blocks\n  \n  # Cluster logging\n  cluster_enabled_log_types = ["api", "audit", "authenticator", "controllerManager", "scheduler"]\n  \n  # Node groups\n  eks_managed_node_groups = {\n    general = {\n      desired_size = 2\n      max_size     = 10\n      min_size     = 1\n      \n      instance_types = ["t3.medium"]\n      capacity_type  = "ON_DEMAND"\n      \n      k8s_labels = {\n        Environment = var.environment\n        NodeGroup   = "general"\n      }\n      \n      update_config = {\n        max_unavailable_percentage = 25\n      }\n    }\n    \n    spot = {\n      desired_size = 2\n      max_size     = 5\n      min_size     = 0\n      \n      instance_types = ["t3.medium", "t3a.medium", "t2.medium"]\n      capacity_type  = "SPOT"\n      \n      k8s_labels = {\n        Environment = var.environment\n        NodeGroup   = "spot"\n      }\n      \n      taints = {\n        spot = {\n          key    = "spot"\n          value  = "true"\n          effect = "NO_SCHEDULE"\n        }\n      }\n    }\n  }\n  \n  tags = local.common_tags\n}\n\n# RDS Database\nresource "aws_db_subnet_group" "main" {\n  name       = "${var.project_name}-${var.environment}-db-subnet-group"\n  subnet_ids = module.vpc.private_subnets\n  \n  tags = merge(local.common_tags, {\n    Name = "${var.project_name}-${var.environment}-db-subnet-group"\n  })\n}\n\nresource "aws_db_instance" "main" {\n  identifier = "${var.project_name}-${var.environment}-db"\n  \n  engine         = "postgres"\n  engine_version = "15.4"\n  instance_class = var.db_instance_class\n  \n  allocated_storage     = 20\n  max_allocated_storage = 100\n  storage_type         = "gp3"\n  storage_encrypted    = true\n  \n  db_name  = var.db_name\n  username = var.db_username\n  password = var.db_password\n  \n  vpc_security_group_ids = [aws_security_group.rds.id]\n  db_subnet_group_name   = aws_db_subnet_group.main.name\n  \n  backup_retention_period = var.environment == "production" ? 7 : 1\n  backup_window          = "03:00-04:00"\n  maintenance_window     = "sun:04:00-sun:05:00"\n  \n  skip_final_snapshot = var.environment != "production"\n  deletion_protection = var.environment == "production"\n  \n  performance_insights_enabled = true\n  monitoring_interval         = 60\n  monitoring_role_arn        = aws_iam_role.rds_monitoring.arn\n  \n  tags = local.common_tags\n}\n\n# S3 Buckets with versioning and encryption\nresource "aws_s3_bucket" "app_data" {\n  bucket = "${var.project_name}-${var.environment}-app-data-${random_string.bucket_suffix.result}"\n  \n  tags = local.common_tags\n}\n\nresource "aws_s3_bucket_versioning" "app_data" {\n  bucket = aws_s3_bucket.app_data.id\n  versioning_configuration {\n    status = "Enabled"\n  }\n}\n\nresource "aws_s3_bucket_server_side_encryption_configuration" "app_data" {\n  bucket = aws_s3_bucket.app_data.id\n  \n  rule {\n    apply_server_side_encryption_by_default {\n      sse_algorithm = "AES256"\n    }\n  }\n}\n\nresource "aws_s3_bucket_public_access_block" "app_data" {\n  bucket = aws_s3_bucket.app_data.id\n  \n  block_public_acls       = true\n  block_public_policy     = true\n  ignore_public_acls      = true\n  restrict_public_buckets = true\n}\n\n# CloudWatch Log Groups\nresource "aws_cloudwatch_log_group" "app_logs" {\n  name              = "/aws/application/${var.project_name}-${var.environment}"\n  retention_in_days = var.environment == "production" ? 30 : 7\n  \n  tags = local.common_tags\n}\n\n# Random string for unique resource naming\nresource "random_string" "bucket_suffix" {\n  length  = 8\n  special = false\n  upper   = false\n}\n'})}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Variables and Outputs:"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-hcl",children:'# variables.tf\nvariable "aws_region" {\n  description = "AWS region"\n  type        = string\n  default     = "us-west-2"\n}\n\nvariable "environment" {\n  description = "Environment name"\n  type        = string\n  validation {\n    condition     = contains(["dev", "staging", "production"], var.environment)\n    error_message = "Environment must be dev, staging, or production."\n  }\n}\n\nvariable "project_name" {\n  description = "Project name"\n  type        = string\n}\n\nvariable "owner" {\n  description = "Resource owner"\n  type        = string\n}\n\nvariable "cost_center" {\n  description = "Cost center for billing"\n  type        = string\n}\n\nvariable "allowed_cidr_blocks" {\n  description = "CIDR blocks allowed to access EKS cluster"\n  type        = list(string)\n  default     = ["0.0.0.0/0"]\n}\n\nvariable "db_instance_class" {\n  description = "RDS instance class"\n  type        = string\n  default     = "db.t3.micro"\n}\n\nvariable "db_name" {\n  description = "Database name"\n  type        = string\n}\n\nvariable "db_username" {\n  description = "Database username"\n  type        = string\n}\n\nvariable "db_password" {\n  description = "Database password"\n  type        = string\n  sensitive   = true\n}\n\n# outputs.tf\noutput "vpc_id" {\n  description = "VPC ID"\n  value       = module.vpc.vpc_id\n}\n\noutput "private_subnets" {\n  description = "Private subnet IDs"\n  value       = module.vpc.private_subnets\n}\n\noutput "public_subnets" {\n  description = "Public subnet IDs"\n  value       = module.vpc.public_subnets\n}\n\noutput "eks_cluster_endpoint" {\n  description = "EKS cluster endpoint"\n  value       = module.eks.cluster_endpoint\n}\n\noutput "eks_cluster_name" {\n  description = "EKS cluster name"\n  value       = module.eks.cluster_name\n}\n\noutput "rds_endpoint" {\n  description = "RDS endpoint"\n  value       = aws_db_instance.main.endpoint\n  sensitive   = true\n}\n\noutput "load_balancer_dns" {\n  description = "Load balancer DNS name"\n  value       = aws_lb.main.dns_name\n}\n'})}),"\n",(0,a.jsx)(e.h3,{id:"multi-cloud-infrastructure-patterns",children:"Multi-Cloud Infrastructure Patterns"}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Azure Resource Manager (ARM) Template:"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-json",children:'{\n  "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",\n  "contentVersion": "1.0.0.0",\n  "parameters": {\n    "environment": {\n      "type": "string",\n      "allowedValues": ["dev", "staging", "production"],\n      "metadata": {\n        "description": "Environment name"\n      }\n    },\n    "projectName": {\n      "type": "string",\n      "metadata": {\n        "description": "Project name for resource naming"\n      }\n    },\n    "location": {\n      "type": "string",\n      "defaultValue": "[resourceGroup().location]",\n      "metadata": {\n        "description": "Location for all resources"\n      }\n    }\n  },\n  "variables": {\n    "vnetName": "[concat(parameters(\'projectName\'), \'-\', parameters(\'environment\'), \'-vnet\')]",\n    "subnetName": "[concat(parameters(\'projectName\'), \'-\', parameters(\'environment\'), \'-subnet\')]",\n    "nsgName": "[concat(parameters(\'projectName\'), \'-\', parameters(\'environment\'), \'-nsg\')]",\n    "aksName": "[concat(parameters(\'projectName\'), \'-\', parameters(\'environment\'), \'-aks\')]",\n    "acrName": "[concat(parameters(\'projectName\'), parameters(\'environment\'), \'acr\', uniqueString(resourceGroup().id))]",\n    "logAnalyticsName": "[concat(parameters(\'projectName\'), \'-\', parameters(\'environment\'), \'-logs\')]"\n  },\n  "resources": [\n    {\n      "type": "Microsoft.Network/virtualNetworks",\n      "apiVersion": "2021-02-01",\n      "name": "[variables(\'vnetName\')]",\n      "location": "[parameters(\'location\')]",\n      "properties": {\n        "addressSpace": {\n          "addressPrefixes": ["10.0.0.0/16"]\n        },\n        "subnets": [\n          {\n            "name": "[variables(\'subnetName\')]",\n            "properties": {\n              "addressPrefix": "10.0.1.0/24",\n              "networkSecurityGroup": {\n                "id": "[resourceId(\'Microsoft.Network/networkSecurityGroups\', variables(\'nsgName\'))]"\n              }\n            }\n          }\n        ]\n      },\n      "dependsOn": [\n        "[resourceId(\'Microsoft.Network/networkSecurityGroups\', variables(\'nsgName\'))]"\n      ]\n    },\n    {\n      "type": "Microsoft.Network/networkSecurityGroups",\n      "apiVersion": "2021-02-01",\n      "name": "[variables(\'nsgName\')]",\n      "location": "[parameters(\'location\')]",\n      "properties": {\n        "securityRules": [\n          {\n            "name": "AllowHTTPS",\n            "properties": {\n              "protocol": "Tcp",\n              "sourcePortRange": "*",\n              "destinationPortRange": "443",\n              "sourceAddressPrefix": "*",\n              "destinationAddressPrefix": "*",\n              "access": "Allow",\n              "priority": 1000,\n              "direction": "Inbound"\n            }\n          }\n        ]\n      }\n    },\n    {\n      "type": "Microsoft.ContainerRegistry/registries",\n      "apiVersion": "2021-06-01-preview",\n      "name": "[variables(\'acrName\')]",\n      "location": "[parameters(\'location\')]",\n      "sku": {\n        "name": "Basic"\n      },\n      "properties": {\n        "adminUserEnabled": false\n      }\n    },\n    {\n      "type": "Microsoft.OperationalInsights/workspaces",\n      "apiVersion": "2021-06-01",\n      "name": "[variables(\'logAnalyticsName\')]",\n      "location": "[parameters(\'location\')]",\n      "properties": {\n        "sku": {\n          "name": "PerGB2018"\n        },\n        "retentionInDays": 30\n      }\n    },\n    {\n      "type": "Microsoft.ContainerService/managedClusters",\n      "apiVersion": "2021-05-01",\n      "name": "[variables(\'aksName\')]",\n      "location": "[parameters(\'location\')]",\n      "identity": {\n        "type": "SystemAssigned"\n      },\n      "properties": {\n        "dnsPrefix": "[concat(parameters(\'projectName\'), \'-\', parameters(\'environment\'))]",\n        "agentPoolProfiles": [\n          {\n            "name": "nodepool1",\n            "count": 2,\n            "vmSize": "Standard_D2s_v3",\n            "osType": "Linux",\n            "mode": "System",\n            "vnetSubnetID": "[resourceId(\'Microsoft.Network/virtualNetworks/subnets\', variables(\'vnetName\'), variables(\'subnetName\'))]"\n          }\n        ],\n        "servicePrincipalProfile": {\n          "clientId": "msi"\n        },\n        "addonProfiles": {\n          "omsagent": {\n            "enabled": true,\n            "config": {\n              "logAnalyticsWorkspaceResourceID": "[resourceId(\'Microsoft.OperationalInsights/workspaces\', variables(\'logAnalyticsName\'))]"\n            }\n          }\n        }\n      },\n      "dependsOn": [\n        "[resourceId(\'Microsoft.Network/virtualNetworks\', variables(\'vnetName\'))]",\n        "[resourceId(\'Microsoft.OperationalInsights/workspaces\', variables(\'logAnalyticsName\'))]"\n      ]\n    }\n  ],\n  "outputs": {\n    "aksClusterName": {\n      "type": "string",\n      "value": "[variables(\'aksName\')]"\n    },\n    "acrLoginServer": {\n      "type": "string",\n      "value": "[reference(resourceId(\'Microsoft.ContainerRegistry/registries\', variables(\'acrName\'))).loginServer]"\n    }\n  }\n}\n'})}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Google Cloud Deployment Manager:"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-yaml",children:'# gcp-infrastructure.yaml\nimports:\n- path: templates/vpc.py\n- path: templates/gke.py\n- path: templates/cloudsql.py\n\nresources:\n- name: vpc-network\n  type: templates/vpc.py\n  properties:\n    project: $(env["project"])\n    region: us-central1\n    \n- name: gke-cluster\n  type: templates/gke.py\n  properties:\n    project: $(env["project"])\n    zone: us-central1-a\n    network: $(ref.vpc-network.selfLink)\n    \n- name: postgres-instance\n  type: templates/cloudsql.py\n  properties:\n    project: $(env["project"])\n    region: us-central1\n    tier: db-f1-micro\n'})}),"\n",(0,a.jsx)(e.h3,{id:"free-resources",children:"Free Resources"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://www.terraform.io/docs",children:"Terraform Documentation"})," - Complete Terraform reference"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://aws.amazon.com/cloudformation/templates/",children:"AWS CloudFormation Templates"})," - Pre-built infrastructure templates"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/",children:"Azure Resource Manager Templates"})," - ARM template documentation"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://cloud.google.com/deployment-manager/docs",children:"Google Cloud Deployment Manager"})," - GCP infrastructure automation"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"2-configuration-management",children:"2. Configuration Management"}),"\n",(0,a.jsx)(e.h3,{id:"ansible-automation",children:"Ansible Automation"}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Advanced Ansible Playbooks:"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-yaml",children:"# site.yml - Main playbook\n---\n- name: Configure web servers\n  hosts: webservers\n  become: yes\n  vars:\n    app_name: myapp\n    app_version: \"{{ lookup('env', 'APP_VERSION') | default('latest') }}\"\n    app_port: 8080\n    nginx_port: 80\n  \n  pre_tasks:\n    - name: Update package cache\n      package:\n        update_cache: yes\n      when: ansible_os_family == \"Debian\"\n    \n    - name: Install required packages\n      package:\n        name:\n          - curl\n          - wget\n          - unzip\n          - htop\n        state: present\n\n  roles:\n    - common\n    - docker\n    - nginx\n    - monitoring\n    - security\n\n  post_tasks:\n    - name: Verify application is running\n      uri:\n        url: \"http://localhost:{{ nginx_port }}/health\"\n        method: GET\n        status_code: 200\n      retries: 5\n      delay: 10\n\n- name: Configure database servers\n  hosts: dbservers\n  become: yes\n  vars:\n    postgres_version: 13\n    postgres_port: 5432\n    \n  roles:\n    - common\n    - postgresql\n    - monitoring\n    - security\n    - backup\n\n- name: Configure load balancers\n  hosts: loadbalancers\n  become: yes\n  vars:\n    backend_servers: \"{{ groups['webservers'] }}\"\n    \n  roles:\n    - common\n    - haproxy\n    - monitoring\n    - security\n"})}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Complex Role Structure:"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-yaml",children:'# roles/docker/tasks/main.yml\n---\n- name: Add Docker GPG key\n  apt_key:\n    url: https://download.docker.com/linux/ubuntu/gpg\n    state: present\n  when: ansible_os_family == "Debian"\n\n- name: Add Docker repository\n  apt_repository:\n    repo: "deb [arch=amd64] https://download.docker.com/linux/ubuntu {{ ansible_distribution_release }} stable"\n    state: present\n  when: ansible_os_family == "Debian"\n\n- name: Install Docker\n  package:\n    name: docker-ce\n    state: present\n\n- name: Start and enable Docker service\n  systemd:\n    name: docker\n    state: started\n    enabled: yes\n\n- name: Add users to docker group\n  user:\n    name: "{{ item }}"\n    groups: docker\n    append: yes\n  loop: "{{ docker_users | default([]) }}"\n\n- name: Install Docker Compose\n  pip:\n    name: docker-compose\n    state: present\n\n- name: Configure Docker daemon\n  template:\n    src: daemon.json.j2\n    dest: /etc/docker/daemon.json\n    backup: yes\n  notify: restart docker\n\n- name: Deploy application containers\n  docker_compose:\n    project_name: "{{ app_name }}"\n    definition:\n      version: \'3.8\'\n      services:\n        app:\n          image: "{{ app_image }}:{{ app_version }}"\n          ports:\n            - "{{ app_port }}:{{ app_port }}"\n          environment:\n            - DATABASE_URL={{ database_url }}\n            - REDIS_URL={{ redis_url }}\n          volumes:\n            - app_data:/app/data\n          restart: unless-stopped\n          healthcheck:\n            test: ["CMD", "curl", "-f", "http://localhost:{{ app_port }}/health"]\n            interval: 30s\n            timeout: 10s\n            retries: 3\n        \n        redis:\n          image: redis:7-alpine\n          ports:\n            - "6379:6379"\n          volumes:\n            - redis_data:/data\n          restart: unless-stopped\n      \n      volumes:\n        app_data:\n        redis_data:\n  register: docker_compose_result\n\n- name: Wait for application to be ready\n  uri:\n    url: "http://localhost:{{ app_port }}/health"\n    method: GET\n    status_code: 200\n  retries: 30\n  delay: 10\n  when: docker_compose_result.changed\n'})}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Dynamic Inventory and Vault Integration:"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python3\n# dynamic_inventory.py - AWS EC2 dynamic inventory\nimport boto3\nimport json\nimport argparse\n\nclass EC2Inventory:\n    def __init__(self):\n        self.inventory = {}\n        self.read_cli_args()\n        \n        if self.args.list:\n            self.inventory = self.get_inventory()\n        elif self.args.host:\n            self.inventory = self.get_host_info(self.args.host)\n        \n        print(json.dumps(self.inventory, indent=2))\n    \n    def read_cli_args(self):\n        parser = argparse.ArgumentParser()\n        parser.add_argument('--list', action='store_true')\n        parser.add_argument('--host', action='store')\n        self.args = parser.parse_args()\n    \n    def get_inventory(self):\n        ec2 = boto3.client('ec2')\n        \n        inventory = {\n            '_meta': {\n                'hostvars': {}\n            }\n        }\n        \n        # Get all running instances\n        response = ec2.describe_instances(\n            Filters=[\n                {'Name': 'instance-state-name', 'Values': ['running']}\n            ]\n        )\n        \n        for reservation in response['Reservations']:\n            for instance in reservation['Instances']:\n                # Get instance details\n                instance_id = instance['InstanceId']\n                private_ip = instance.get('PrivateIpAddress', '')\n                public_ip = instance.get('PublicIpAddress', '')\n                \n                # Get tags\n                tags = {tag['Key']: tag['Value'] for tag in instance.get('Tags', [])}\n                \n                # Group by environment\n                environment = tags.get('Environment', 'untagged')\n                if environment not in inventory:\n                    inventory[environment] = {'hosts': []}\n                \n                # Group by role\n                role = tags.get('Role', 'untagged')\n                if role not in inventory:\n                    inventory[role] = {'hosts': []}\n                \n                # Add to groups\n                inventory[environment]['hosts'].append(private_ip)\n                inventory[role]['hosts'].append(private_ip)\n                \n                # Add host variables\n                inventory['_meta']['hostvars'][private_ip] = {\n                    'instance_id': instance_id,\n                    'public_ip': public_ip,\n                    'instance_type': instance['InstanceType'],\n                    'tags': tags,\n                    'ansible_host': public_ip if public_ip else private_ip\n                }\n        \n        return inventory\n    \n    def get_host_info(self, hostname):\n        return {}\n\nif __name__ == '__main__':\n    EC2Inventory()\n"})}),"\n",(0,a.jsx)(e.h3,{id:"infrastructure-testing-and-validation",children:"Infrastructure Testing and Validation"}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Ansible Testing with Molecule:"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-yaml",children:"# molecule/default/molecule.yml\n---\ndependency:\n  name: galaxy\ndriver:\n  name: docker\nplatforms:\n  - name: instance\n    image: quay.io/ansible/molecule-ubuntu:18.04\n    pre_build_image: true\nprovisioner:\n  name: ansible\n  inventory:\n    host_vars:\n      instance:\n        app_name: testapp\n        app_version: latest\nverifier:\n  name: ansible\n"})}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Infrastructure Testing with Terratest:"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-go",children:'// test/terraform_test.go\npackage test\n\nimport (\n    "testing"\n    "time"\n    \n    "github.com/gruntwork-io/terratest/modules/aws"\n    "github.com/gruntwork-io/terratest/modules/terraform"\n    "github.com/stretchr/testify/assert"\n)\n\nfunc TestTerraformInfrastructure(t *testing.T) {\n    t.Parallel()\n    \n    // Configure Terraform options\n    terraformOptions := &terraform.Options{\n        TerraformDir: "../",\n        Vars: map[string]interface{}{\n            "environment":   "test",\n            "project_name":  "terratest",\n            "aws_region":    "us-west-2",\n            "db_name":       "testdb",\n            "db_username":   "testuser",\n            "db_password":   "testpass123",\n        },\n    }\n    \n    // Clean up resources after test\n    defer terraform.Destroy(t, terraformOptions)\n    \n    // Deploy infrastructure\n    terraform.InitAndApply(t, terraformOptions)\n    \n    // Test VPC creation\n    vpcId := terraform.Output(t, terraformOptions, "vpc_id")\n    assert.NotEmpty(t, vpcId)\n    \n    // Verify VPC exists in AWS\n    aws.GetVpcById(t, vpcId, "us-west-2")\n    \n    // Test EKS cluster\n    clusterName := terraform.Output(t, terraformOptions, "eks_cluster_name")\n    assert.NotEmpty(t, clusterName)\n    \n    // Verify EKS cluster is active\n    cluster := aws.GetEksCluster(t, "us-west-2", clusterName)\n    assert.Equal(t, "ACTIVE", *cluster.Status)\n    \n    // Test RDS instance\n    rdsEndpoint := terraform.Output(t, terraformOptions, "rds_endpoint")\n    assert.NotEmpty(t, rdsEndpoint)\n    \n    // Test Load Balancer\n    lbDns := terraform.Output(t, terraformOptions, "load_balancer_dns")\n    assert.NotEmpty(t, lbDns)\n    \n    // Additional validation can be added here\n    // - Test network connectivity\n    // - Verify security groups\n    // - Check resource tags\n    // - Validate backup configurations\n}\n\nfunc TestInfrastructureCompliance(t *testing.T) {\n    t.Parallel()\n    \n    terraformOptions := &terraform.Options{\n        TerraformDir: "../",\n        PlanFilePath: "./terraform.plan",\n    }\n    \n    // Generate plan\n    terraform.InitAndPlan(t, terraformOptions)\n    \n    // Parse plan for compliance checks\n    plan := terraform.ShowWithStruct(t, terraformOptions)\n    \n    // Check that all resources have required tags\n    for _, resource := range plan.PlannedValues.RootModule.Resources {\n        if resource.Type == "aws_instance" || \n           resource.Type == "aws_db_instance" ||\n           resource.Type == "aws_s3_bucket" {\n            \n            tags := resource.Values["tags"].(map[string]interface{})\n            assert.Contains(t, tags, "Environment")\n            assert.Contains(t, tags, "Project")\n            assert.Contains(t, tags, "ManagedBy")\n        }\n    }\n    \n    // Check encryption settings\n    for _, resource := range plan.PlannedValues.RootModule.Resources {\n        if resource.Type == "aws_s3_bucket" {\n            // Verify S3 bucket has encryption\n            assert.True(t, hasEncryption(resource))\n        }\n        \n        if resource.Type == "aws_db_instance" {\n            // Verify RDS has encryption\n            storageEncrypted := resource.Values["storage_encrypted"].(bool)\n            assert.True(t, storageEncrypted)\n        }\n    }\n}\n\nfunc hasEncryption(resource *terraform.PlannedValue) bool {\n    // Implementation to check if resource has encryption enabled\n    // This would depend on the specific resource type and configuration\n    return true\n}\n'})}),"\n",(0,a.jsx)(e.h3,{id:"free-resources-1",children:"Free Resources"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://docs.ansible.com/",children:"Ansible Documentation"})," - Complete Ansible automation guide"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://molecule.readthedocs.io/",children:"Molecule Testing Framework"})," - Ansible role testing"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://terratest.gruntwork.io/",children:"Terratest"})," - Infrastructure testing framework"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://docs.chef.io/",children:"Chef Infra Documentation"})," - Configuration management with Chef"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"3-state-management-and-collaboration",children:"3. State Management and Collaboration"}),"\n",(0,a.jsx)(e.h3,{id:"advanced-state-management",children:"Advanced State Management"}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Terraform Remote State and Locking:"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-hcl",children:'# backend.tf - Remote state configuration\nterraform {\n  backend "s3" {\n    bucket         = "terraform-state-bucket"\n    key            = "environments/production/terraform.tfstate"\n    region         = "us-west-2"\n    encrypt        = true\n    dynamodb_table = "terraform-locks"\n    \n    # Workspace-specific state files\n    workspace_key_prefix = "workspaces"\n  }\n}\n\n# State bucket creation (separate configuration)\nresource "aws_s3_bucket" "terraform_state" {\n  bucket = "terraform-state-bucket"\n  \n  lifecycle {\n    prevent_destroy = true\n  }\n}\n\nresource "aws_s3_bucket_versioning" "terraform_state" {\n  bucket = aws_s3_bucket.terraform_state.id\n  versioning_configuration {\n    status = "Enabled"\n  }\n}\n\nresource "aws_s3_bucket_server_side_encryption_configuration" "terraform_state" {\n  bucket = aws_s3_bucket.terraform_state.id\n  \n  rule {\n    apply_server_side_encryption_by_default {\n      sse_algorithm = "AES256"\n    }\n  }\n}\n\nresource "aws_s3_bucket_public_access_block" "terraform_state" {\n  bucket = aws_s3_bucket.terraform_state.id\n  \n  block_public_acls       = true\n  block_public_policy     = true\n  ignore_public_acls      = true\n  restrict_public_buckets = true\n}\n\nresource "aws_dynamodb_table" "terraform_locks" {\n  name           = "terraform-locks"\n  billing_mode   = "PAY_PER_REQUEST"\n  hash_key       = "LockID"\n  \n  attribute {\n    name = "LockID"\n    type = "S"\n  }\n  \n  tags = {\n    Name = "Terraform State Lock Table"\n  }\n}\n'})}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Workspace Management Script:"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:'#!/bin/bash\n# terraform-workspace-manager.sh\n\nset -euo pipefail\n\nSCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"\nPROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"\n\n# Configuration\nENVIRONMENTS=("dev" "staging" "production")\nTERRAFORM_DIR="$PROJECT_ROOT/terraform"\n\n# Colors for output\nRED=\'\\033[0;31m\'\nGREEN=\'\\033[0;32m\'\nYELLOW=\'\\033[1;33m\'\nNC=\'\\033[0m\' # No Color\n\nlog() {\n    echo -e "${GREEN}[$(date +\'%Y-%m-%d %H:%M:%S\')] $1${NC}"\n}\n\nwarn() {\n    echo -e "${YELLOW}[$(date +\'%Y-%m-%d %H:%M:%S\')] WARNING: $1${NC}"\n}\n\nerror() {\n    echo -e "${RED}[$(date +\'%Y-%m-%d %H:%M:%S\')] ERROR: $1${NC}"\n    exit 1\n}\n\ncheck_prerequisites() {\n    log "Checking prerequisites..."\n    \n    # Check if terraform is installed\n    if ! command -v terraform &> /dev/null; then\n        error "Terraform is not installed"\n    fi\n    \n    # Check if AWS CLI is configured\n    if ! aws sts get-caller-identity &> /dev/null; then\n        error "AWS CLI is not configured or credentials are invalid"\n    fi\n    \n    # Check if terraform directory exists\n    if [[ ! -d "$TERRAFORM_DIR" ]]; then\n        error "Terraform directory not found: $TERRAFORM_DIR"\n    fi\n    \n    log "Prerequisites check passed"\n}\n\ninit_terraform() {\n    local env=$1\n    log "Initializing Terraform for environment: $env"\n    \n    cd "$TERRAFORM_DIR"\n    \n    # Initialize terraform\n    terraform init -reconfigure\n    \n    # Create or select workspace\n    if terraform workspace list | grep -q "$env"; then\n        terraform workspace select "$env"\n    else\n        terraform workspace new "$env"\n    fi\n    \n    log "Terraform initialized for environment: $env"\n}\n\nplan_infrastructure() {\n    local env=$1\n    log "Planning infrastructure for environment: $env"\n    \n    cd "$TERRAFORM_DIR"\n    terraform workspace select "$env"\n    \n    # Generate plan\n    terraform plan \\\n        -var-file="environments/${env}.tfvars" \\\n        -out="${env}.tfplan"\n    \n    log "Plan generated for environment: $env"\n}\n\napply_infrastructure() {\n    local env=$1\n    log "Applying infrastructure for environment: $env"\n    \n    cd "$TERRAFORM_DIR"\n    terraform workspace select "$env"\n    \n    # Apply the plan\n    if [[ -f "${env}.tfplan" ]]; then\n        terraform apply "${env}.tfplan"\n        rm "${env}.tfplan"\n    else\n        warn "No plan file found, running apply with auto-approve"\n        terraform apply \\\n            -var-file="environments/${env}.tfvars" \\\n            -auto-approve\n    fi\n    \n    log "Infrastructure applied for environment: $env"\n}\n\ndestroy_infrastructure() {\n    local env=$1\n    \n    if [[ "$env" == "production" ]]; then\n        error "Cannot destroy production environment with this script"\n    fi\n    \n    warn "This will destroy all infrastructure in environment: $env"\n    read -p "Are you sure? Type \'yes\' to confirm: " confirmation\n    \n    if [[ "$confirmation" != "yes" ]]; then\n        log "Destruction cancelled"\n        return\n    fi\n    \n    log "Destroying infrastructure for environment: $env"\n    \n    cd "$TERRAFORM_DIR"\n    terraform workspace select "$env"\n    \n    terraform destroy \\\n        -var-file="environments/${env}.tfvars" \\\n        -auto-approve\n    \n    log "Infrastructure destroyed for environment: $env"\n}\n\nvalidate_configuration() {\n    local env=$1\n    log "Validating configuration for environment: $env"\n    \n    cd "$TERRAFORM_DIR"\n    terraform workspace select "$env"\n    \n    # Validate syntax\n    terraform validate\n    \n    # Format check\n    terraform fmt -check=true -diff=true\n    \n    # Security scan (if tfsec is installed)\n    if command -v tfsec &> /dev/null; then\n        tfsec .\n    fi\n    \n    log "Configuration validation passed for environment: $env"\n}\n\nshow_usage() {\n    cat << EOF\nUsage: $0 <command> <environment>\n\nCommands:\n    init        Initialize Terraform for environment\n    plan        Generate execution plan\n    apply       Apply infrastructure changes\n    destroy     Destroy infrastructure (not allowed for production)\n    validate    Validate configuration\n    \nEnvironments:\n    dev         Development environment\n    staging     Staging environment\n    production  Production environment\n\nExamples:\n    $0 init dev\n    $0 plan staging\n    $0 apply production\n    $0 validate dev\nEOF\n}\n\nmain() {\n    if [[ $# -lt 2 ]]; then\n        show_usage\n        exit 1\n    fi\n    \n    local command=$1\n    local environment=$2\n    \n    # Validate environment\n    if [[ ! " ${ENVIRONMENTS[@]} " =~ " ${environment} " ]]; then\n        error "Invalid environment: $environment"\n    fi\n    \n    check_prerequisites\n    \n    case $command in\n        init)\n            init_terraform "$environment"\n            ;;\n        plan)\n            init_terraform "$environment"\n            plan_infrastructure "$environment"\n            ;;\n        apply)\n            init_terraform "$environment"\n            apply_infrastructure "$environment"\n            ;;\n        destroy)\n            init_terraform "$environment"\n            destroy_infrastructure "$environment"\n            ;;\n        validate)\n            init_terraform "$environment"\n            validate_configuration "$environment"\n            ;;\n        *)\n            error "Unknown command: $command"\n            ;;\n    esac\n}\n\nmain "$@"\n'})}),"\n",(0,a.jsx)(e.h3,{id:"free-resources-2",children:"Free Resources"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://www.terraform.io/docs/language/state/index.html",children:"Terraform State Management"})," - State management best practices"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://docs.ansible.com/ansible/latest/user_guide/vault.html",children:"Ansible Vault"})," - Secrets management"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://pre-commit.com/",children:"Git Hooks for Infrastructure"})," - Pre-commit hooks for IaC"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://www.hashicorp.com/blog/testing-hashicorp-terraform",children:"Infrastructure Testing Guide"})," - Testing strategies"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"hands-on-exercises",children:"Hands-On Exercises"}),"\n",(0,a.jsx)(e.h3,{id:"exercise-1-multi-cloud-infrastructure-deployment",children:"Exercise 1: Multi-Cloud Infrastructure Deployment"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Task:"})," Deploy identical infrastructure across AWS, Azure, and GCP."]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Requirements:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Use Terraform with provider-specific modules"}),"\n",(0,a.jsx)(e.li,{children:"Implement consistent tagging and naming conventions"}),"\n",(0,a.jsx)(e.li,{children:"Set up monitoring and logging for all environments"}),"\n",(0,a.jsx)(e.li,{children:"Create automated testing and validation"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"exercise-2-configuration-management-at-scale",children:"Exercise 2: Configuration Management at Scale"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Task:"})," Configure 100+ servers with Ansible using dynamic inventory."]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Requirements:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Dynamic inventory from cloud providers"}),"\n",(0,a.jsx)(e.li,{children:"Role-based configuration management"}),"\n",(0,a.jsx)(e.li,{children:"Secrets management with Ansible Vault"}),"\n",(0,a.jsx)(e.li,{children:"Automated testing with Molecule"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"exercise-3-infrastructure-state-management",children:"Exercise 3: Infrastructure State Management"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Task:"})," Implement enterprise-grade state management and collaboration."]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Requirements:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Remote state with locking"}),"\n",(0,a.jsx)(e.li,{children:"Workspace management for multiple environments"}),"\n",(0,a.jsx)(e.li,{children:"State backup and recovery procedures"}),"\n",(0,a.jsx)(e.li,{children:"Team collaboration workflows"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"assessment-questions",children:"Assessment Questions"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Design a multi-cloud infrastructure strategy that ensures consistency and portability."})}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Implement a comprehensive configuration management solution for a large-scale deployment."})}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Create a state management strategy that supports team collaboration and prevents conflicts."})}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Design infrastructure testing and validation pipelines for continuous compliance."})}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Develop a disaster recovery plan for infrastructure state and configuration."})}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,a.jsx)(e.p,{children:"After completing this module:"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Deploy production infrastructure"})," using IaC best practices"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Implement configuration management"})," at enterprise scale"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Master state management"})," and team collaboration"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Move to Module 4: Containerization and Orchestration"})," to learn container platforms"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,a.jsx)(e.h3,{id:"tools-and-platforms",children:"Tools and Platforms"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://cloud.hashicorp.com/products/terraform",children:"Terraform Cloud"})," - Terraform collaboration platform"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://www.ansible.com/products/tower",children:"Ansible Tower/AWX"})," - Ansible automation platform"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://www.pulumi.com/",children:"Pulumi"})," - Modern infrastructure as code"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://aws.amazon.com/cdk/",children:"CDK (Cloud Development Kit)"})," - Infrastructure as code using programming languages"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"advanced-topics",children:"Advanced Topics"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://terragrunt.gruntwork.io/",children:"Terragrunt"})," - Terraform wrapper for DRY configurations"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://www.runatlantis.io/",children:"Atlantis"})," - Terraform pull request automation"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://www.checkov.io/",children:"Checkov"})," - Static code analysis for infrastructure"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.a,{href:"https://www.infracost.io/",children:"Infracost"})," - Cloud cost estimation for Terraform"]}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:["Ready to master containers and orchestration? Continue to ",(0,a.jsx)(e.strong,{children:"Module 4: Containerization and Orchestration"})," to learn Docker and Kubernetes!"]})]})}function u(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(d,{...n})}):d(n)}},8453:(n,e,r)=>{r.d(e,{R:()=>o,x:()=>i});var t=r(6540);const a={},s=t.createContext(a);function o(n){const e=t.useContext(s);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function i(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:o(n.components),t.createElement(s.Provider,{value:e},n.children)}}}]);