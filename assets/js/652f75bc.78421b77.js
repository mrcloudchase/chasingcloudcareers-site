"use strict";(self.webpackChunkchasingcloudcareers=self.webpackChunkchasingcloudcareers||[]).push([[9217],{8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var s=t(6540);const r={},i=s.createContext(r);function a(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),s.createElement(i.Provider,{value:n},e.children)}},9010:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>a,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"devops-engineering/cicd-pipelines","title":"CI/CD Pipelines and Automation","description":"Master continuous integration and continuous deployment practices, building robust automated pipelines that enable rapid, reliable software delivery at scale.","source":"@site/docs/devops-engineering/02-cicd-pipelines.md","sourceDirName":"devops-engineering","slug":"/devops-engineering/cicd-pipelines","permalink":"/chasingcloudcareers-site/docs/devops-engineering/cicd-pipelines","draft":false,"unlisted":false,"editUrl":"https://github.com/mrcloudchase/chasingcloudcareers-site/tree/main/docs/devops-engineering/02-cicd-pipelines.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"DevOps Fundamentals and Culture","permalink":"/chasingcloudcareers-site/docs/devops-engineering/devops-fundamentals"},"next":{"title":"Infrastructure as Code and Configuration Management","permalink":"/chasingcloudcareers-site/docs/devops-engineering/infrastructure-as-code"}}');var r=t(4848),i=t(8453);const a={sidebar_position:4},o="CI/CD Pipelines and Automation",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"1. Continuous Integration Fundamentals",id:"1-continuous-integration-fundamentals",level:2},{value:"CI Pipeline Architecture",id:"ci-pipeline-architecture",level:3},{value:"Advanced Testing Strategies",id:"advanced-testing-strategies",level:3},{value:"Free Resources",id:"free-resources",level:3},{value:"2. Continuous Deployment Strategies",id:"2-continuous-deployment-strategies",level:2},{value:"Deployment Patterns",id:"deployment-patterns",level:3},{value:"Rollback and Recovery Strategies",id:"rollback-and-recovery-strategies",level:3},{value:"Free Resources",id:"free-resources-1",level:3},{value:"3. Pipeline Optimization and Troubleshooting",id:"3-pipeline-optimization-and-troubleshooting",level:2},{value:"Performance Optimization",id:"performance-optimization",level:3},{value:"Free Resources",id:"free-resources-2",level:3},{value:"Hands-On Exercises",id:"hands-on-exercises",level:2},{value:"Exercise 1: Complete CI/CD Pipeline Implementation",id:"exercise-1-complete-cicd-pipeline-implementation",level:3},{value:"Exercise 2: Advanced Deployment Strategy",id:"exercise-2-advanced-deployment-strategy",level:3},{value:"Exercise 3: Pipeline Optimization Project",id:"exercise-3-pipeline-optimization-project",level:3},{value:"Assessment Questions",id:"assessment-questions",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"Additional Resources",id:"additional-resources",level:2},{value:"Tools and Platforms",id:"tools-and-platforms",level:3},{value:"Advanced Topics",id:"advanced-topics",level:3}];function u(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"cicd-pipelines-and-automation",children:"CI/CD Pipelines and Automation"})}),"\n",(0,r.jsx)(n.p,{children:"Master continuous integration and continuous deployment practices, building robust automated pipelines that enable rapid, reliable software delivery at scale."}),"\n",(0,r.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,r.jsx)(n.p,{children:"By the end of this module, you will:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Design and implement comprehensive CI/CD pipelines"}),"\n",(0,r.jsx)(n.li,{children:"Master automated testing strategies and quality assurance"}),"\n",(0,r.jsx)(n.li,{children:"Build sophisticated deployment automation with rollback capabilities"}),"\n",(0,r.jsx)(n.li,{children:"Optimize pipeline performance and troubleshoot complex issues"}),"\n",(0,r.jsx)(n.li,{children:"Integrate multiple tools and platforms in cohesive workflows"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"1-continuous-integration-fundamentals",children:"1. Continuous Integration Fundamentals"}),"\n",(0,r.jsx)(n.h3,{id:"ci-pipeline-architecture",children:"CI Pipeline Architecture"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Core CI Components:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"# .github/workflows/ci.yml - GitHub Actions CI Pipeline\nname: Continuous Integration\n\non:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n    branches: [ main ]\n\nenv:\n  NODE_VERSION: '18'\n  PYTHON_VERSION: '3.11'\n\njobs:\n  code-quality:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n      \n      - name: Install dependencies\n        run: npm ci\n      \n      - name: Lint code\n        run: npm run lint\n      \n      - name: Format check\n        run: npm run format:check\n      \n      - name: Type check\n        run: npm run type-check\n\n  security-scan:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Run security audit\n        run: npm audit --audit-level=moderate\n      \n      - name: Scan for secrets\n        uses: trufflesecurity/trufflehog@main\n        with:\n          path: ./\n          base: main\n          head: HEAD\n\n  unit-tests:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        node-version: [16, 18, 20]\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Setup Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'npm'\n      \n      - name: Install dependencies\n        run: npm ci\n      \n      - name: Run unit tests\n        run: npm run test:unit -- --coverage\n      \n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n        with:\n          file: ./coverage/lcov.info\n\n  integration-tests:\n    runs-on: ubuntu-latest\n    services:\n      postgres:\n        image: postgres:15\n        env:\n          POSTGRES_PASSWORD: postgres\n          POSTGRES_DB: testdb\n        options: >-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n      \n      redis:\n        image: redis:7\n        options: >-\n          --health-cmd \"redis-cli ping\"\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n    \n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n      \n      - name: Install dependencies\n        run: npm ci\n      \n      - name: Run database migrations\n        run: npm run db:migrate\n        env:\n          DATABASE_URL: postgres://postgres:postgres@localhost:5432/testdb\n      \n      - name: Run integration tests\n        run: npm run test:integration\n        env:\n          DATABASE_URL: postgres://postgres:postgres@localhost:5432/testdb\n          REDIS_URL: redis://localhost:6379\n\n  build:\n    runs-on: ubuntu-latest\n    needs: [code-quality, security-scan, unit-tests, integration-tests]\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n      \n      - name: Install dependencies\n        run: npm ci\n      \n      - name: Build application\n        run: npm run build\n      \n      - name: Build Docker image\n        run: |\n          docker build -t myapp:${{ github.sha }} .\n          docker tag myapp:${{ github.sha }} myapp:latest\n      \n      - name: Save Docker image\n        run: docker save myapp:${{ github.sha }} | gzip > myapp-image.tar.gz\n      \n      - name: Upload build artifacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: build-artifacts\n          path: |\n            dist/\n            myapp-image.tar.gz\n"})}),"\n",(0,r.jsx)(n.h3,{id:"advanced-testing-strategies",children:"Advanced Testing Strategies"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Test Pyramid Implementation:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"// Unit Tests (70% of test suite)\n// tests/unit/userService.test.js\nimport { describe, it, expect, jest } from '@jest/globals';\nimport { UserService } from '../../src/services/UserService.js';\nimport { UserRepository } from '../../src/repositories/UserRepository.js';\n\njest.mock('../../src/repositories/UserRepository.js');\n\ndescribe('UserService', () => {\n  let userService;\n  let mockUserRepository;\n\n  beforeEach(() => {\n    mockUserRepository = new UserRepository();\n    userService = new UserService(mockUserRepository);\n  });\n\n  describe('createUser', () => {\n    it('should create user with valid data', async () => {\n      const userData = {\n        email: 'test@example.com',\n        name: 'Test User',\n        password: 'securePassword123'\n      };\n\n      mockUserRepository.findByEmail.mockResolvedValue(null);\n      mockUserRepository.create.mockResolvedValue({ id: 1, ...userData });\n\n      const result = await userService.createUser(userData);\n\n      expect(result).toEqual({ id: 1, ...userData });\n      expect(mockUserRepository.findByEmail).toHaveBeenCalledWith(userData.email);\n      expect(mockUserRepository.create).toHaveBeenCalledWith(userData);\n    });\n\n    it('should throw error for duplicate email', async () => {\n      const userData = { email: 'existing@example.com' };\n      mockUserRepository.findByEmail.mockResolvedValue({ id: 1 });\n\n      await expect(userService.createUser(userData))\n        .rejects.toThrow('User with this email already exists');\n    });\n  });\n});\n\n// Integration Tests (20% of test suite)\n// tests/integration/userAPI.test.js\nimport request from 'supertest';\nimport { app } from '../../src/app.js';\nimport { database } from '../../src/database.js';\n\ndescribe('User API Integration', () => {\n  beforeAll(async () => {\n    await database.migrate.latest();\n  });\n\n  afterAll(async () => {\n    await database.destroy();\n  });\n\n  beforeEach(async () => {\n    await database.seed.run();\n  });\n\n  describe('POST /api/users', () => {\n    it('should create user and return 201', async () => {\n      const userData = {\n        email: 'newuser@example.com',\n        name: 'New User',\n        password: 'securePassword123'\n      };\n\n      const response = await request(app)\n        .post('/api/users')\n        .send(userData)\n        .expect(201);\n\n      expect(response.body).toMatchObject({\n        id: expect.any(Number),\n        email: userData.email,\n        name: userData.name\n      });\n      expect(response.body.password).toBeUndefined();\n    });\n  });\n});\n\n// End-to-End Tests (10% of test suite)\n// tests/e2e/userRegistration.test.js\nimport { test, expect } from '@playwright/test';\n\ntest.describe('User Registration Flow', () => {\n  test('should complete full registration process', async ({ page }) => {\n    // Navigate to registration page\n    await page.goto('/register');\n    \n    // Fill registration form\n    await page.fill('[data-testid=\"email-input\"]', 'e2e@example.com');\n    await page.fill('[data-testid=\"name-input\"]', 'E2E Test User');\n    await page.fill('[data-testid=\"password-input\"]', 'securePassword123');\n    await page.fill('[data-testid=\"confirm-password-input\"]', 'securePassword123');\n    \n    // Submit form\n    await page.click('[data-testid=\"register-button\"]');\n    \n    // Verify success\n    await expect(page.locator('[data-testid=\"success-message\"]'))\n      .toContainText('Registration successful');\n    \n    // Verify redirect to dashboard\n    await expect(page).toHaveURL('/dashboard');\n    \n    // Verify user is logged in\n    await expect(page.locator('[data-testid=\"user-menu\"]'))\n      .toContainText('E2E Test User');\n  });\n});\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Performance and Load Testing:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"// tests/performance/loadTest.js\nimport http from 'k6/http';\nimport { check, sleep } from 'k6';\nimport { Rate } from 'k6/metrics';\n\nexport let errorRate = new Rate('errors');\n\nexport let options = {\n  stages: [\n    { duration: '2m', target: 100 }, // Ramp up to 100 users\n    { duration: '5m', target: 100 }, // Stay at 100 users\n    { duration: '2m', target: 200 }, // Ramp up to 200 users\n    { duration: '5m', target: 200 }, // Stay at 200 users\n    { duration: '2m', target: 0 },   // Ramp down to 0 users\n  ],\n  thresholds: {\n    http_req_duration: ['p(99)<1500'], // 99% of requests must complete below 1.5s\n    http_req_failed: ['rate<0.1'],     // Error rate must be below 10%\n    errors: ['rate<0.1'],              // Custom error rate\n  },\n};\n\nexport default function () {\n  // Test user registration\n  let registrationPayload = JSON.stringify({\n    email: `user${Math.random()}@example.com`,\n    name: 'Load Test User',\n    password: 'testPassword123'\n  });\n\n  let registrationResponse = http.post(\n    'http://localhost:3000/api/users',\n    registrationPayload,\n    {\n      headers: { 'Content-Type': 'application/json' },\n    }\n  );\n\n  let registrationSuccess = check(registrationResponse, {\n    'registration status is 201': (r) => r.status === 201,\n    'registration response time < 500ms': (r) => r.timings.duration < 500,\n  });\n\n  errorRate.add(!registrationSuccess);\n\n  if (registrationSuccess) {\n    // Test user login\n    let loginPayload = JSON.stringify({\n      email: JSON.parse(registrationPayload).email,\n      password: 'testPassword123'\n    });\n\n    let loginResponse = http.post(\n      'http://localhost:3000/api/auth/login',\n      loginPayload,\n      {\n        headers: { 'Content-Type': 'application/json' },\n      }\n    );\n\n    let loginSuccess = check(loginResponse, {\n      'login status is 200': (r) => r.status === 200,\n      'login response time < 300ms': (r) => r.timings.duration < 300,\n      'login returns token': (r) => JSON.parse(r.body).token !== undefined,\n    });\n\n    errorRate.add(!loginSuccess);\n  }\n\n  sleep(1);\n}\n"})}),"\n",(0,r.jsx)(n.h3,{id:"free-resources",children:"Free Resources"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://docs.github.com/en/actions",children:"GitHub Actions Documentation"})," - Complete CI/CD with GitHub Actions"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://docs.gitlab.com/ee/ci/",children:"GitLab CI/CD Guide"})," - Comprehensive GitLab CI/CD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://www.jenkins.io/doc/book/",children:"Jenkins User Handbook"})," - Open source automation server"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://testing.googleblog.com/",children:"Testing Best Practices - Google"})," - Testing strategies and techniques"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"2-continuous-deployment-strategies",children:"2. Continuous Deployment Strategies"}),"\n",(0,r.jsx)(n.h3,{id:"deployment-patterns",children:"Deployment Patterns"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Blue-Green Deployment:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'# .github/workflows/blue-green-deploy.yml\nname: Blue-Green Deployment\n\non:\n  push:\n    branches: [ main ]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Determine current environment\n        id: current-env\n        run: |\n          CURRENT=$(curl -s https://api.example.com/health | jq -r \'.environment // "blue"\')\n          if [ "$CURRENT" = "blue" ]; then\n            echo "current=blue" >> $GITHUB_OUTPUT\n            echo "target=green" >> $GITHUB_OUTPUT\n          else\n            echo "current=green" >> $GITHUB_OUTPUT\n            echo "target=blue" >> $GITHUB_OUTPUT\n          fi\n      \n      - name: Deploy to target environment\n        run: |\n          echo "Deploying to ${{ steps.current-env.outputs.target }} environment"\n          \n          # Deploy application to target environment\n          kubectl set image deployment/myapp-${{ steps.current-env.outputs.target }} \\\n            app=myapp:${{ github.sha }} \\\n            -n production\n          \n          # Wait for rollout to complete\n          kubectl rollout status deployment/myapp-${{ steps.current-env.outputs.target }} \\\n            -n production --timeout=300s\n      \n      - name: Run smoke tests\n        run: |\n          TARGET_URL="https://${{ steps.current-env.outputs.target }}.example.com"\n          \n          # Health check\n          curl -f "$TARGET_URL/health" || exit 1\n          \n          # Basic functionality tests\n          npm run test:smoke -- --baseUrl="$TARGET_URL"\n      \n      - name: Switch traffic\n        run: |\n          # Update load balancer to point to new environment\n          kubectl patch service myapp-service \\\n            -p \'{"spec":{"selector":{"version":"${{ steps.current-env.outputs.target }}"}}}\' \\\n            -n production\n          \n          echo "Traffic switched to ${{ steps.current-env.outputs.target }} environment"\n      \n      - name: Verify deployment\n        run: |\n          # Wait for DNS propagation and verify\n          sleep 30\n          curl -f https://api.example.com/health\n          \n          # Run full test suite against production\n          npm run test:production\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Canary Deployment with Istio:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'# canary-deployment.yaml\napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: myapp-rollout\nspec:\n  replicas: 10\n  strategy:\n    canary:\n      steps:\n      - setWeight: 10\n      - pause: {duration: 2m}\n      - setWeight: 20\n      - pause: {duration: 2m}\n      - setWeight: 50\n      - pause: {duration: 2m}\n      - setWeight: 100\n      canaryService: myapp-canary\n      stableService: myapp-stable\n      trafficRouting:\n        istio:\n          virtualService:\n            name: myapp-vs\n            routes:\n            - primary\n      analysis:\n        templates:\n        - templateName: success-rate\n        args:\n        - name: service-name\n          value: myapp-canary\n        - name: prometheus-server\n          value: http://prometheus:9090\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n      - name: myapp\n        image: myapp:latest\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            memory: "128Mi"\n            cpu: "100m"\n          limits:\n            memory: "256Mi"\n            cpu: "200m"\n\n---\napiVersion: argoproj.io/v1alpha1\nkind: AnalysisTemplate\nmetadata:\n  name: success-rate\nspec:\n  args:\n  - name: service-name\n  - name: prometheus-server\n  metrics:\n  - name: success-rate\n    interval: 30s\n    count: 5\n    successCondition: result[0] >= 0.95\n    failureLimit: 3\n    provider:\n      prometheus:\n        address: "{{args.prometheus-server}}"\n        query: |\n          sum(rate(http_requests_total{service="{{args.service-name}}",status!~"5.."}[2m])) /\n          sum(rate(http_requests_total{service="{{args.service-name}}"}[2m]))\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Feature Flag Deployment:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"// Feature flag implementation\nclass FeatureFlags {\n  constructor(configService) {\n    this.configService = configService;\n    this.flags = new Map();\n    this.loadFlags();\n  }\n\n  async loadFlags() {\n    try {\n      const flags = await this.configService.getFeatureFlags();\n      flags.forEach(flag => {\n        this.flags.set(flag.name, flag);\n      });\n    } catch (error) {\n      console.error('Failed to load feature flags:', error);\n    }\n  }\n\n  isEnabled(flagName, context = {}) {\n    const flag = this.flags.get(flagName);\n    if (!flag) return false;\n\n    // Global enable/disable\n    if (!flag.enabled) return false;\n\n    // User-based rollout\n    if (flag.userRollout && context.userId) {\n      const userHash = this.hashUserId(context.userId);\n      return userHash < flag.userRollout.percentage;\n    }\n\n    // Environment-based rollout\n    if (flag.environmentRollout) {\n      return flag.environmentRollout.includes(context.environment);\n    }\n\n    // Time-based rollout\n    if (flag.timeRollout) {\n      const now = new Date();\n      const startTime = new Date(flag.timeRollout.startTime);\n      const endTime = new Date(flag.timeRollout.endTime);\n      return now >= startTime && now <= endTime;\n    }\n\n    return flag.defaultValue || false;\n  }\n\n  hashUserId(userId) {\n    // Simple hash function for user-based rollouts\n    let hash = 0;\n    for (let i = 0; i < userId.length; i++) {\n      const char = userId.charCodeAt(i);\n      hash = ((hash << 5) - hash) + char;\n      hash = hash & hash; // Convert to 32-bit integer\n    }\n    return Math.abs(hash) % 100;\n  }\n}\n\n// Usage in application\nconst featureFlags = new FeatureFlags(configService);\n\napp.get('/api/users', async (req, res) => {\n  const useNewUserAPI = featureFlags.isEnabled('new-user-api', {\n    userId: req.user.id,\n    environment: process.env.NODE_ENV\n  });\n\n  if (useNewUserAPI) {\n    return newUserController.getUsers(req, res);\n  } else {\n    return legacyUserController.getUsers(req, res);\n  }\n});\n"})}),"\n",(0,r.jsx)(n.h3,{id:"rollback-and-recovery-strategies",children:"Rollback and Recovery Strategies"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Automated Rollback Pipeline:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'# .github/workflows/rollback.yml\nname: Automated Rollback\n\non:\n  workflow_dispatch:\n    inputs:\n      target_version:\n        description: \'Version to rollback to\'\n        required: true\n      environment:\n        description: \'Environment to rollback\'\n        required: true\n        type: choice\n        options:\n        - staging\n        - production\n\njobs:\n  rollback:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Validate rollback target\n        run: |\n          # Verify target version exists\n          if ! git rev-parse --verify ${{ github.event.inputs.target_version }}; then\n            echo "Invalid target version: ${{ github.event.inputs.target_version }}"\n            exit 1\n          fi\n          \n          # Verify target version is older than current\n          CURRENT_COMMIT=$(kubectl get deployment myapp -o jsonpath=\'{.metadata.annotations.deployment\\.kubernetes\\.io/revision}\')\n          if [ "${{ github.event.inputs.target_version }}" = "$CURRENT_COMMIT" ]; then\n            echo "Target version is the same as current version"\n            exit 1\n          fi\n      \n      - name: Create rollback backup\n        run: |\n          # Backup current state before rollback\n          kubectl get deployment myapp -o yaml > rollback-backup-$(date +%Y%m%d-%H%M%S).yaml\n          \n          # Store backup in artifact\n          echo "BACKUP_FILE=rollback-backup-$(date +%Y%m%d-%H%M%S).yaml" >> $GITHUB_ENV\n      \n      - name: Execute rollback\n        run: |\n          echo "Rolling back to version: ${{ github.event.inputs.target_version }}"\n          \n          # Rollback deployment\n          kubectl rollout undo deployment/myapp --to-revision=${{ github.event.inputs.target_version }}\n          \n          # Wait for rollback to complete\n          kubectl rollout status deployment/myapp --timeout=300s\n      \n      - name: Verify rollback\n        run: |\n          # Health check\n          kubectl wait --for=condition=available deployment/myapp --timeout=300s\n          \n          # Application health check\n          HEALTH_URL="https://${{ github.event.inputs.environment }}.example.com/health"\n          curl -f "$HEALTH_URL" || exit 1\n          \n          # Run smoke tests\n          npm run test:smoke -- --baseUrl="https://${{ github.event.inputs.environment }}.example.com"\n      \n      - name: Notify team\n        if: always()\n        run: |\n          STATUS="${{ job.status }}"\n          if [ "$STATUS" = "success" ]; then\n            MESSAGE="\u2705 Rollback to ${{ github.event.inputs.target_version }} completed successfully"\n          else\n            MESSAGE="\u274c Rollback to ${{ github.event.inputs.target_version }} failed"\n          fi\n          \n          curl -X POST -H \'Content-type: application/json\' \\\n            --data "{\\"text\\":\\"$MESSAGE\\"}" \\\n            ${{ secrets.SLACK_WEBHOOK_URL }}\n      \n      - name: Upload backup\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: rollback-backup\n          path: ${{ env.BACKUP_FILE }}\n'})}),"\n",(0,r.jsx)(n.h3,{id:"free-resources-1",children:"Free Resources"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://argoproj.github.io/argo-rollouts/",children:"Argo Rollouts Documentation"})," - Advanced deployment strategies"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://istio.io/latest/docs/concepts/traffic-management/",children:"Istio Traffic Management"})," - Service mesh deployments"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://launchdarkly.com/blog/",children:"Feature Flags Guide - LaunchDarkly"})," - Feature flag best practices"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",children:"Deployment Strategies - Kubernetes"})," - Kubernetes deployment patterns"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"3-pipeline-optimization-and-troubleshooting",children:"3. Pipeline Optimization and Troubleshooting"}),"\n",(0,r.jsx)(n.h3,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Pipeline Caching Strategies:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"# Optimized GitHub Actions with caching\nname: Optimized CI Pipeline\n\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      \n      # Cache dependencies\n      - name: Cache Node modules\n        uses: actions/cache@v3\n        with:\n          path: ~/.npm\n          key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}\n          restore-keys: |\n            ${{ runner.os }}-node-\n      \n      # Cache Docker layers\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n      \n      - name: Cache Docker layers\n        uses: actions/cache@v3\n        with:\n          path: /tmp/.buildx-cache\n          key: ${{ runner.os }}-buildx-${{ github.sha }}\n          restore-keys: |\n            ${{ runner.os }}-buildx-\n      \n      # Parallel job execution\n      - name: Install dependencies\n        run: npm ci\n      \n      - name: Run linting and tests in parallel\n        run: |\n          npm run lint &\n          npm run test:unit &\n          npm run test:integration &\n          wait\n      \n      # Optimized Docker build\n      - name: Build Docker image\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          push: false\n          tags: myapp:latest\n          cache-from: type=local,src=/tmp/.buildx-cache\n          cache-to: type=local,dest=/tmp/.buildx-cache-new,mode=max\n      \n      # Move cache to avoid ever-growing cache\n      - name: Move cache\n        run: |\n          rm -rf /tmp/.buildx-cache\n          mv /tmp/.buildx-cache-new /tmp/.buildx-cache\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Pipeline Monitoring and Metrics:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\n\"\"\"\nCI/CD Pipeline Monitoring and Analytics\n\"\"\"\nimport requests\nimport json\nimport time\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nclass PipelineMonitor:\n    def __init__(self, github_token, repo_owner, repo_name):\n        self.github_token = github_token\n        self.repo_owner = repo_owner\n        self.repo_name = repo_name\n        self.base_url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}\"\n        self.headers = {\n            'Authorization': f'token {github_token}',\n            'Accept': 'application/vnd.github.v3+json'\n        }\n    \n    def get_workflow_runs(self, days=30):\n        \"\"\"Get workflow runs from the last N days\"\"\"\n        since = (datetime.now() - timedelta(days=days)).isoformat()\n        url = f\"{self.base_url}/actions/runs\"\n        \n        params = {\n            'created': f'>={since}',\n            'per_page': 100\n        }\n        \n        response = requests.get(url, headers=self.headers, params=params)\n        response.raise_for_status()\n        \n        return response.json()['workflow_runs']\n    \n    def analyze_pipeline_performance(self, runs):\n        \"\"\"Analyze pipeline performance metrics\"\"\"\n        metrics = {\n            'total_runs': len(runs),\n            'success_rate': 0,\n            'failure_rate': 0,\n            'avg_duration': 0,\n            'builds_per_day': 0,\n            'slowest_jobs': [],\n            'failure_reasons': {}\n        }\n        \n        if not runs:\n            return metrics\n        \n        # Success/failure rates\n        successful_runs = [r for r in runs if r['conclusion'] == 'success']\n        failed_runs = [r for r in runs if r['conclusion'] == 'failure']\n        \n        metrics['success_rate'] = len(successful_runs) / len(runs) * 100\n        metrics['failure_rate'] = len(failed_runs) / len(runs) * 100\n        \n        # Average duration (in minutes)\n        durations = []\n        for run in runs:\n            if run['created_at'] and run['updated_at']:\n                created = datetime.fromisoformat(run['created_at'].replace('Z', '+00:00'))\n                updated = datetime.fromisoformat(run['updated_at'].replace('Z', '+00:00'))\n                duration = (updated - created).total_seconds() / 60\n                durations.append(duration)\n        \n        metrics['avg_duration'] = sum(durations) / len(durations) if durations else 0\n        \n        # Builds per day\n        days_span = (datetime.now() - datetime.fromisoformat(runs[-1]['created_at'].replace('Z', '+00:00'))).days\n        metrics['builds_per_day'] = len(runs) / max(days_span, 1)\n        \n        return metrics\n    \n    def get_job_details(self, run_id):\n        \"\"\"Get detailed job information for a workflow run\"\"\"\n        url = f\"{self.base_url}/actions/runs/{run_id}/jobs\"\n        response = requests.get(url, headers=self.headers)\n        response.raise_for_status()\n        \n        return response.json()['jobs']\n    \n    def identify_bottlenecks(self, runs, sample_size=10):\n        \"\"\"Identify performance bottlenecks in recent runs\"\"\"\n        bottlenecks = []\n        \n        # Analyze recent runs\n        recent_runs = runs[:sample_size]\n        \n        for run in recent_runs:\n            jobs = self.get_job_details(run['id'])\n            \n            for job in jobs:\n                if job['started_at'] and job['completed_at']:\n                    started = datetime.fromisoformat(job['started_at'].replace('Z', '+00:00'))\n                    completed = datetime.fromisoformat(job['completed_at'].replace('Z', '+00:00'))\n                    duration = (completed - started).total_seconds() / 60\n                    \n                    bottlenecks.append({\n                        'job_name': job['name'],\n                        'duration': duration,\n                        'run_id': run['id'],\n                        'status': job['conclusion']\n                    })\n        \n        # Sort by duration to find slowest jobs\n        bottlenecks.sort(key=lambda x: x['duration'], reverse=True)\n        \n        return bottlenecks[:10]  # Top 10 slowest jobs\n    \n    def generate_report(self):\n        \"\"\"Generate comprehensive pipeline report\"\"\"\n        print(\"Generating CI/CD Pipeline Report...\")\n        \n        # Get workflow runs\n        runs = self.get_workflow_runs(30)\n        \n        # Analyze performance\n        metrics = self.analyze_pipeline_performance(runs)\n        \n        # Identify bottlenecks\n        bottlenecks = self.identify_bottlenecks(runs)\n        \n        # Generate report\n        report = f\"\"\"\nCI/CD Pipeline Performance Report\nGenerated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n=== OVERVIEW ===\nTotal Runs (30 days): {metrics['total_runs']}\nSuccess Rate: {metrics['success_rate']:.1f}%\nFailure Rate: {metrics['failure_rate']:.1f}%\nAverage Duration: {metrics['avg_duration']:.1f} minutes\nBuilds per Day: {metrics['builds_per_day']:.1f}\n\n=== PERFORMANCE BOTTLENECKS ===\nTop 5 Slowest Jobs:\n\"\"\"\n        \n        for i, bottleneck in enumerate(bottlenecks[:5], 1):\n            report += f\"{i}. {bottleneck['job_name']}: {bottleneck['duration']:.1f} minutes\\n\"\n        \n        report += f\"\"\"\n=== RECOMMENDATIONS ===\n\"\"\"\n        \n        # Generate recommendations based on metrics\n        if metrics['avg_duration'] > 15:\n            report += \"- Consider optimizing build times with better caching\\n\"\n        \n        if metrics['failure_rate'] > 10:\n            report += \"- High failure rate detected, review test stability\\n\"\n        \n        if metrics['builds_per_day'] > 50:\n            report += \"- Consider implementing build queuing or parallel execution\\n\"\n        \n        return report\n    \n    def create_dashboard(self, runs):\n        \"\"\"Create visual dashboard of pipeline metrics\"\"\"\n        # Prepare data\n        df = pd.DataFrame([\n            {\n                'date': datetime.fromisoformat(run['created_at'].replace('Z', '+00:00')).date(),\n                'status': run['conclusion'],\n                'duration': self._calculate_duration(run)\n            }\n            for run in runs\n        ])\n        \n        # Create subplots\n        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n        \n        # Success rate over time\n        daily_stats = df.groupby(['date', 'status']).size().unstack(fill_value=0)\n        if 'success' in daily_stats.columns and 'failure' in daily_stats.columns:\n            success_rate = daily_stats['success'] / (daily_stats['success'] + daily_stats['failure']) * 100\n            ax1.plot(success_rate.index, success_rate.values)\n            ax1.set_title('Success Rate Over Time')\n            ax1.set_ylabel('Success Rate (%)')\n        \n        # Build duration distribution\n        ax2.hist(df['duration'].dropna(), bins=20, alpha=0.7)\n        ax2.set_title('Build Duration Distribution')\n        ax2.set_xlabel('Duration (minutes)')\n        ax2.set_ylabel('Frequency')\n        \n        # Builds per day\n        builds_per_day = df.groupby('date').size()\n        ax3.bar(builds_per_day.index, builds_per_day.values)\n        ax3.set_title('Builds per Day')\n        ax3.set_ylabel('Number of Builds')\n        \n        # Status distribution\n        status_counts = df['status'].value_counts()\n        ax4.pie(status_counts.values, labels=status_counts.index, autopct='%1.1f%%')\n        ax4.set_title('Build Status Distribution')\n        \n        plt.tight_layout()\n        plt.savefig('pipeline_dashboard.png', dpi=300, bbox_inches='tight')\n        plt.show()\n    \n    def _calculate_duration(self, run):\n        \"\"\"Calculate run duration in minutes\"\"\"\n        if run['created_at'] and run['updated_at']:\n            created = datetime.fromisoformat(run['created_at'].replace('Z', '+00:00'))\n            updated = datetime.fromisoformat(run['updated_at'].replace('Z', '+00:00'))\n            return (updated - created).total_seconds() / 60\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    monitor = PipelineMonitor(\n        github_token=\"your_github_token\",\n        repo_owner=\"your_org\",\n        repo_name=\"your_repo\"\n    )\n    \n    # Generate report\n    report = monitor.generate_report()\n    print(report)\n    \n    # Create dashboard\n    runs = monitor.get_workflow_runs(30)\n    monitor.create_dashboard(runs)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"free-resources-2",children:"Free Resources"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://docs.gitlab.com/ee/ci/pipelines/pipeline_efficiency.html",children:"Pipeline Optimization Guide - GitLab"})," - Performance optimization techniques"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://docs.github.com/en/actions/learn-github-actions/usage-limits-billing-and-administration",children:"GitHub Actions Best Practices"})," - Optimization and limits"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://www.jenkins.io/doc/book/scaling/",children:"Jenkins Performance Tuning"})," - Scaling and optimization"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://www.atlassian.com/continuous-delivery/principles/continuous-integration-vs-delivery-vs-deployment",children:"CI/CD Metrics and KPIs"})," - Measuring pipeline success"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"hands-on-exercises",children:"Hands-On Exercises"}),"\n",(0,r.jsx)(n.h3,{id:"exercise-1-complete-cicd-pipeline-implementation",children:"Exercise 1: Complete CI/CD Pipeline Implementation"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Task:"})," Build a comprehensive CI/CD pipeline for a web application."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Requirements:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Multi-stage pipeline with quality gates"}),"\n",(0,r.jsx)(n.li,{children:"Automated testing at multiple levels"}),"\n",(0,r.jsx)(n.li,{children:"Security scanning and compliance checks"}),"\n",(0,r.jsx)(n.li,{children:"Deployment automation with rollback capabilities"}),"\n",(0,r.jsx)(n.li,{children:"Monitoring and alerting integration"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"exercise-2-advanced-deployment-strategy",children:"Exercise 2: Advanced Deployment Strategy"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Task:"})," Implement canary deployment with automated rollback."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Requirements:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Canary deployment configuration"}),"\n",(0,r.jsx)(n.li,{children:"Automated performance monitoring"}),"\n",(0,r.jsx)(n.li,{children:"Success criteria definition"}),"\n",(0,r.jsx)(n.li,{children:"Automatic rollback triggers"}),"\n",(0,r.jsx)(n.li,{children:"Traffic splitting and management"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"exercise-3-pipeline-optimization-project",children:"Exercise 3: Pipeline Optimization Project"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Task:"})," Optimize an existing slow CI/CD pipeline."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Requirements:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Performance analysis and bottleneck identification"}),"\n",(0,r.jsx)(n.li,{children:"Caching strategy implementation"}),"\n",(0,r.jsx)(n.li,{children:"Parallel execution optimization"}),"\n",(0,r.jsx)(n.li,{children:"Resource usage optimization"}),"\n",(0,r.jsx)(n.li,{children:"Before/after performance comparison"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"assessment-questions",children:"Assessment Questions"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Design a CI/CD pipeline that ensures zero-downtime deployments for a critical production system."})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Compare different deployment strategies (blue-green, canary, rolling) and their trade-offs."})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Implement automated rollback mechanisms with proper monitoring and alerting."})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Create a comprehensive testing strategy that balances speed and coverage."})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Design a pipeline optimization strategy for a high-frequency deployment environment."})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsx)(n.p,{children:"After completing this module:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Build production-ready pipelines"})," with comprehensive testing and deployment automation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Implement advanced deployment strategies"})," in real-world scenarios"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Optimize pipeline performance"})," and troubleshoot complex issues"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Move to Module 3: Infrastructure as Code"})," to automate infrastructure provisioning"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,r.jsx)(n.h3,{id:"tools-and-platforms",children:"Tools and Platforms"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://github.com/features/actions",children:"GitHub Actions"})," - Native GitHub CI/CD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://docs.gitlab.com/ee/ci/",children:"GitLab CI/CD"})," - Integrated DevOps platform"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://www.jenkins.io/",children:"Jenkins"})," - Open source automation server"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://circleci.com/",children:"CircleCI"})," - Cloud-based CI/CD platform"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"advanced-topics",children:"Advanced Topics"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://argoproj.github.io/argo-cd/",children:"Argo CD"})," - GitOps continuous delivery"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://tekton.dev/",children:"Tekton"})," - Kubernetes-native CI/CD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://spinnaker.io/",children:"Spinnaker"})," - Multi-cloud continuous delivery"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://fluxcd.io/",children:"Flux"})," - GitOps toolkit for Kubernetes"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Ready to automate your infrastructure? Continue to ",(0,r.jsx)(n.strong,{children:"Module 3: Infrastructure as Code and Configuration Management"})," to master infrastructure automation!"]})]})}function d(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(u,{...e})}):u(e)}}}]);